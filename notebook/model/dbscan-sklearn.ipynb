{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DBSCAN as clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"INITIAL\",\"login\",\"View_Items\",\"home\",\"logout\",\"View_Items_quantity\",\"Add_to_Cart\",\"shoppingcart\",\n",
    "          \"remove\",\"deferorder\",\"purchasecart\",\"inventory\",\"sellinventory\",\"clearcart\",\"cancelorder\",\"$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = {'HZKS0-WG8pZr0eCsZlBAP5Xm': ['login',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'home',\n",
    "  'logout'],\n",
    " '5tPgZbHdK2Zp+heFBs8HsMkx': ['login',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'shoppingcart',\n",
    "  'remove',\n",
    "  'deferorder',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'RU2oCVNdpWEM0-2x7I5OjPbZ': ['login',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'View_Items_quantity',\n",
    "  'Add_to_Cart',\n",
    "  'purchasecart',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'kG4g0E5mqwRYcsQOCfj+7wG7': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " '8ocO6WP3QaFpBvkooS5INPwe': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'WOTZQBwSCnI+DfDQ-2cS7Mgp': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'e4bMe1HfiUlmvUMmPJU4y1B4': ['login',\n",
    "  'inventory',\n",
    "  'inventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'sellinventory',\n",
    "  'home',\n",
    "  'logout'],\n",
    " 'MEzDpcnm1MQ9GFGox7uP4Ep-': ['login',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'View_Items',\n",
    "  'home',\n",
    "  'logout']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makovchain & sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transition_matrix(sessions, states):\n",
    "    markovchains = []\n",
    "    for key, value in sessions.items():\n",
    "        # labelEncoding\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(value)\n",
    "        transformed_s = le.transform(value)\n",
    "\n",
    "        #factorize\n",
    "        factorize = pd.factorize(value)[0]\n",
    "        \n",
    "        # matrix\n",
    "        n = 1 + max(factorize)  # number of states\n",
    "        M = [[0] * n for _ in range(n)]\n",
    "\n",
    "        for (i, j) in zip(factorize, factorize[1:]):\n",
    "            M[i][j] += 1\n",
    "        \n",
    "        # now convert to probabilities:\n",
    "        for row in M:\n",
    "            s = sum(row)\n",
    "            if s > 0:\n",
    "                row[:] = [f / s for f in row]\n",
    "                \n",
    "        # print Matrix style\n",
    "        #for row in M: print(' '.join('{0:.2f}'.format(x) for x in row))\n",
    "        \n",
    "        # unique array in the right order\n",
    "        value = np.array(value)\n",
    "        _, idx = np.unique(value, return_index=True)\n",
    "        \n",
    "        df = pd.DataFrame(data = M, index=value[np.sort(idx)],\n",
    "                          columns=value[np.sort(idx)])\n",
    "\n",
    "        df_1 = pd.DataFrame(index=states, columns=states, dtype='float64')\n",
    "\n",
    "        #merge = df_1.merge(df, how='right').fillna(0).round(2).set_index(value[np.sort(idx)])\n",
    "        merge = df_1.update(df, join='left')\n",
    "        #merge = pd.merge(df_1, df, how='right').fillna(0).round(2).set_index(value[np.sort(idx)])\n",
    "        \n",
    "        \n",
    "        merge = pd.concat([pd.concat([df_1, df], axis=1, sort= False)], axis=0).fillna(0).round(2).iloc[:, :-n] \n",
    "        #merge = merge.iloc[:, :-n]        \n",
    "        \n",
    "        \n",
    "        # convert into Vector\n",
    "        merge = np.array(merge.values.flatten().tolist())\n",
    "        #print(len(merge))\n",
    "        # resize so the vectors got the same length\n",
    "        #size = 16*16\n",
    "        #merge.resize(size)\n",
    "        \n",
    "        # 2-D array \n",
    "        markovchains.append(merge)\n",
    "        #print(len(markovchains))\n",
    "        # csr sparse matrix\n",
    "        csr = csr_matrix(markovchains)\n",
    "        #print(csr.shape)\n",
    "        #markovchains.append(merge)\n",
    "        \n",
    "    #print(len(merge))\n",
    "    return csr\n",
    "\n",
    "#m = transition_matrix(sessions, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1 -1  0  0  0  0  0]\n",
      "(array([-1,  0], dtype=int64), array([2, 6], dtype=int64))\n",
      "DBSCAN(algorithm='auto', eps=2, leaf_size=30, metric='euclidean',\n",
      "    metric_params=None, min_samples=2, n_jobs=None, p=None)\n"
     ]
    }
   ],
   "source": [
    "X = m\n",
    "clustering = DBSCAN(eps=2, min_samples=2).fit(X)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "print(np.unique(labels, return_counts=True))\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test\n",
    "X = np.arange(100).reshape(20,5)\n",
    "clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    "labels = clustering.labels_M\n",
    "print(labels)\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagate after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data imports\n",
    "PATH = \"../../data/raw/\"\n",
    "sessions_file = (PATH+'sessions.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_request_dict(sessions_file):\n",
    "    s_r_dict = {}\n",
    "    # Dict of sessions\n",
    "    with open(sessions_file) as fn:\n",
    "        sessions_raw = fn.readlines()\n",
    "\n",
    "    for session in sessions_raw:\n",
    "        key = re.search('([^.]+)', session).group()\n",
    "        value = re.findall('\\\"(.*?)\\\"', session)\n",
    "        s_r_dict[key] = value\n",
    "\n",
    "    return s_r_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = session_request_dict(sessions_file)\n",
    "\n",
    "set_1 = {k: data[k] for k in list(data)[0:200]}\n",
    "set_2 = {k: data[k] for k in list(data)[100:300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict_Cluster\n",
    "def cluster_dict(labels, X_):\n",
    "    cluster_list =[]\n",
    "    \n",
    "    for label in np.unique(labels):\n",
    "        points = X_[labels == label].toarray()\n",
    "        \n",
    "        for point in points:\n",
    "            cluster_dict = {}\n",
    "            cluster_dict[label] = point\n",
    "            cluster_list.append(cluster_dict)\n",
    "            \n",
    "    return cluster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2], dtype=int64), array([105,  49,  46], dtype=int64))\n",
      "(array([0, 1, 2], dtype=int64), array([ 50, 103,  47], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X_1 = transition_matrix(set_1, states)\n",
    "X_2 = transition_matrix(set_2, states)\n",
    "\n",
    "#print('matrix done', datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "#print('start clustering\\n')\n",
    "\n",
    "clustering_1 = DBSCAN(eps=1.5, min_samples=10).fit(X_1)\n",
    "clustering_2 = DBSCAN(eps=1.5, min_samples=10).fit(X_2)\n",
    "\n",
    "labels_1 = clustering_1.labels_\n",
    "labels_2 = clustering_2.labels_\n",
    "\n",
    "# clustering1.components_.toarray()\n",
    "#n_clusters = len(np.unique(labels))\n",
    "first_list = X_1[labels_1 == 2].toarray()\n",
    "second_list = X_2[labels_2 == 2].toarray()\n",
    "\n",
    "\n",
    "cluster_dict_1 = cluster_dict(labels_1, X_1)\n",
    "cluster_dict_2 = cluster_dict(labels_2, X_2)\n",
    "\n",
    "print(np.unique(labels_1, return_counts=True))\n",
    "print(np.unique(labels_2, return_counts=True))\n",
    "#print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_cluster(cluster_dict_):\n",
    "    c0 = []\n",
    "    for item in cluster_dict_:\n",
    "        for k,v in item.items():\n",
    "            if k == 0:\n",
    "                c0.append(v.tolist())\n",
    "    return c0\n",
    "first_list_0 = list_cluster(cluster_dict_1)\n",
    "\n",
    "second_list_0 = list_cluster(cluster_dict_2)\n",
    "\n",
    "\n",
    "def list_cluster(cluster_dict_):\n",
    "    c0 = []\n",
    "    for item in cluster_dict_:\n",
    "        for k,v in item.items():\n",
    "            if k == 1:\n",
    "                c0.append(v.tolist())\n",
    "    return c0\n",
    "first_list_1 = list_cluster(cluster_dict_1)\n",
    "\n",
    "second_list_1 = list_cluster(cluster_dict_2)\n",
    "\n",
    "\n",
    "\n",
    "def list_cluster(cluster_dict_):\n",
    "    c0 = []\n",
    "    for item in cluster_dict_:\n",
    "        for k,v in item.items():\n",
    "            if k == 2:\n",
    "                c0.append(v.tolist())\n",
    "    return c0\n",
    "first_list_2 = list_cluster(cluster_dict_1)\n",
    "\n",
    "second_list_2 = list_cluster(cluster_dict_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "\n",
    "for list in first_list:\n",
    "    if list not in second_list:\n",
    "        differences.append(list)\n",
    "print(len(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "\n",
    "for list in first_list:\n",
    "    if list not in second_list:\n",
    "        differences.append(list)\n",
    "print(len(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "\n",
    "for list in first_list:\n",
    "    if list not in second_list:\n",
    "        differences.append(list)\n",
    "print(len(differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kreuztest Verschiebung der Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "\n",
    "for list in first_list_1:\n",
    "    if list not in second_list_2:\n",
    "        differences.append(list)\n",
    "print(len(differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "    \n",
    "https://stackoverflow.com/questions/18237479/dbscan-in-scikit-learn-of-python-save-the-cluster-points-in-an-array\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dos's: \n",
    "\n",
    "vll noch gemeinsame punkte funden somit gegenbeweis\n",
    "\n",
    "156 Unterschiede somit m√ºssen 44 Punkte gleich geblieben sein.\n",
    "\n",
    "Kreuzunterschiede!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "first_list = [[1, 2], [13, 2]]\n",
    "second_list = [[1, 2], [13, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tuple_list = [tuple(lst) for lst in first_list]\n",
    "second_tuple_list = [tuple(lst) for lst in second_list]\n",
    "#print(first_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_set = set(first_tuple_list)\n",
    "second_set = set(second_tuple_list)\n",
    "#print(first_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_set = set(map(tuple, first_list))\n",
    "second_set = set(map(tuple, second_list))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(first_set) & set(second_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frozenset(first_set).intersection(second_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: \n",
    "\n",
    "https://stackoverflow.com/questions/6105777/how-to-compare-a-list-of-lists-sets-in-python\n",
    "https://stackoverflow.com/questions/1388818/how-can-i-compare-two-lists-in-python-and-return-matches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
